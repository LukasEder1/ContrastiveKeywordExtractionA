{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97a52cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukas/ml/lib/python3.6/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.11) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from contrastive_keyword_extraction import contrastive_extraction, final_score, combine_keywords\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from policy_processing import *\n",
    "from cleantext import clean\n",
    "from baselines import *\n",
    "from tqdm import trange\n",
    "import string\n",
    "import pickle\n",
    "import sentence_comparision\n",
    "import sentence_importance\n",
    "import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f93e9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('../datasets/small10k.sqlite')\n",
    "df = pd.read_sql(\"SELECT * FROM small10k\", con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "885a2b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_func = lambda text : clean(text,\n",
    "    fix_unicode=True,               # fix various unicode errors\n",
    "    to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "    lower=False,                     # lowercase text\n",
    "    no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them\n",
    "    no_urls=False,                  # replace all URLs with a special token\n",
    "    no_emails=False,                # replace all email addresses with a special token\n",
    "    no_phone_numbers=False,         # replace all phone numbers with a special token\n",
    "    no_numbers=False,               # replace all numbers with a special token\n",
    "    no_digits=False,                # replace all digits with a special token\n",
    "    no_currency_symbols=False,      # replace all currency symbols with a special token\n",
    "    no_punct=False,                 # remove punctuations\n",
    "    replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
    "    replace_with_url=\"<URL>\",\n",
    "    replace_with_email=\"<EMAIL>\",\n",
    "    replace_with_phone_number=\"<PHONE>\",\n",
    "    replace_with_number=\"<NUMBER>\",\n",
    "    replace_with_digit=\"0\",\n",
    "    replace_with_currency_symbol=\"<CUR>\",\n",
    "    lang=\"en\"              \n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ee7112b",
   "metadata": {},
   "source": [
    "\n",
    "all_site_ids = list(set(df.site_id))\n",
    "\n",
    "# get all policies with more than 1 version\n",
    "all_usefull_ids = [site_id for site_id in all_site_ids if len(create_data(df, site_id)) > 1]\n",
    "\n",
    "with open(\"usefull_ids.pkl\", \"wb\") as file:\n",
    "    \n",
    "    # write list to file\n",
    "    pickle.dump(all_usefull_ids, file)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1a43421",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"usefull_ids.pkl\", \"rb\") as file:\n",
    "    # read list from file\n",
    "    all_usefull_ids = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f196a451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_collection(df, \n",
    "                      sites, \n",
    "                      ke_extractor = keyword_extraction.extract_yake, \n",
    "                      num_keywords=10,\n",
    "                      max_ngram=2, \n",
    "                      sentence_matcher = sentence_comparision.match_sentences_semantic_search,\n",
    "                      importance_estimator = sentence_importance.text_rank_importance,\n",
    "                      use_furthest=False, \n",
    "                      name_prefix=\"\",\n",
    "                      make_data_persistent=False, \n",
    "                      path=\"dataframes\"):\n",
    "    \n",
    "    for i in trange(len(sites)):\n",
    "\n",
    "        site_id = sites[i]\n",
    "\n",
    "        # sort first by year, then by phase\n",
    "        data = create_data(df.sort_values(by=['year', 'phase']), site_id)\n",
    "\n",
    "        # get_the actual strings\n",
    "        policy_texts = get_policy_texts(data)\n",
    "\n",
    "        # cleaned documents using above function\n",
    "        documents = clean_text(policy_texts, cleaning_func)\n",
    "        \n",
    "        # use only the first and last version\n",
    "        if use_furthest:\n",
    "            documents = [documents[0], documents[-1]]\n",
    "        \n",
    "        # run CKE-pipeline\n",
    "        keywords, matched_dicts, changed_sentences, added, deleted = contrastive_extraction(documents, \n",
    "                                                                     max_ngram=max_ngram,\n",
    "                                                                     min_ngram=1, show_changes=False, \n",
    "                                                                     symbols_to_remove=string.punctuation,\n",
    "                                                                     match_sentences= sentence_matcher,\n",
    "                                                                     importance_estimator= importance_estimator)\n",
    "        \n",
    "        \n",
    "        # save total\n",
    "        total_keywords = combine_keywords(keywords)\n",
    "\n",
    "        total_frame = pd.DataFrame({'keyword' : total_keywords.keys(), 'score': total_keywords.values()})\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # save itermediate\n",
    "        inter_kws, inter_scores, delta_int = create_inter_frame(keywords)\n",
    "        \n",
    "        intermediate_frame = pd.DataFrame({'delta': delta_int, 'keyword': inter_kws, 'score': inter_scores})\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # create CKE on the specified baseline\n",
    "        baseline_keywords = baseline_diff_content(added, lambda x: ke_extractor(x, max_ngram_size=max_ngram,\n",
    "                                                                               numOfKeywords=num_keywords))\n",
    "        \n",
    "        baseline_kws, baseline_scores, delta_list = create_baseline_frame(baseline_keywords)\n",
    "        \n",
    "        baseline_frame = pd.DataFrame({'delta': delta_list, 'keyword': baseline_kws, 'score': baseline_scores})\n",
    "        \n",
    "        \n",
    "        if make_data_persistent:\n",
    "            \n",
    "            intermediate_frame.to_csv(f\"{path}/{name_prefix}_inter_keywords_{site_id}.csv\", index=False)\n",
    "            \n",
    "            total_frame.to_csv(f\"{path}/{name_prefix}_keywords_{site_id}.csv\", index=False)\n",
    "            \n",
    "            baseline_frame.to_csv(f\"{path}/{name_prefix}_baseline_keywords_{site_id}.csv\", index=False)\n",
    "        \n",
    "    \n",
    "    return total_frame, intermediate_frame, baseline_frame"
   ]
  },
  {
   "cell_type": "raw",
   "id": "762722a8",
   "metadata": {},
   "source": [
    "create_collection(df, all_usefull_ids[:100], \n",
    "                  keyword_extraction.extract_yake, \n",
    "                  num_keywords=15, \n",
    "                  max_ngram=2, \n",
    "                  sentence_matcher = sentence_comparision.match_sentences_tfidf_weighted, \n",
    "                  use_furthest=True,\n",
    "                  name_prefix=\"tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3261d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "\n",
    "def cartesian_product(params):\n",
    "    \n",
    "    # gett all possible combinations\n",
    "    return list(product(*params.values()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b825a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"matcher\": [sentence_comparision.match_sentences_semantic_search,\n",
    "                          sentence_comparision.match_sentences_tfidf_weighted],\n",
    "              \n",
    "             \"importance\": [sentence_importance.text_rank_importance, \n",
    "                            sentence_importance.yake_weighted_importance]\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0477778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cartesian_collection(params, \n",
    "                                df,\n",
    "                                sites, \n",
    "                                baseline_ke_extractor = keyword_extraction.extract_yake, \n",
    "                                num_keywords=10, \n",
    "                                max_ngram=2, \n",
    "                                use_furthest=False,\n",
    "                                make_data_persistent=False,\n",
    "                                path=\"dataframes\",\n",
    "                                compare_k = 15):\n",
    "            \n",
    "        \n",
    "    combinations = cartesian_product(params)\n",
    "    \n",
    "    number_of_combinations = len(combinations)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for combination in combinations:\n",
    "        \n",
    "        matcher, importance_estimator = combination\n",
    "        \n",
    "        print(f\"Contrastive Keyword Extraction pipeline is being ran with combination {count}:\")\n",
    "        \n",
    "        total_frame, intermediate_frame, baseline_frame = create_collection(df = df, \n",
    "                                                                  sites = sites, \n",
    "                                                                  ke_extractor = baseline_ke_extractor, \n",
    "                                                                  num_keywords = num_keywords, \n",
    "                                                                  max_ngram = max_ngram, \n",
    "                                                                  sentence_matcher = matcher,\n",
    "                                                                  importance_estimator = importance_estimator,\n",
    "                                                                  use_furthest = use_furthest,\n",
    "                                                                  name_prefix=f\"combination_{count}\",\n",
    "                                                                  make_data_persistent=make_data_persistent,\n",
    "                                                                  path = path)\n",
    "        \n",
    "        \n",
    "        \n",
    "        summary.extensive_summary(sites, \n",
    "                                  show_results=True, \n",
    "                                  k=compare_k,\n",
    "                                  name_a = f\"combination_{count}_inter_keywords\", \n",
    "                                  name_b = f\"combination_{count}_baseline_keywords\",\n",
    "                                  save_prefix=f\"combination_{count}_\", \n",
    "                                  path=path)\n",
    "        \n",
    "        \n",
    "        count += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c4144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrastive Keyword Extraction pipeline is being ran with combination 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:32<00:00,  5.45s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Delta</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>IoU</th>\n",
       "      <th>#overlaps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106506</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98325</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106533</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90158</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>98356</td>\n",
       "      <td>0</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>106560</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>106565</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>98377</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90195</td>\n",
       "      <td>0</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Site  Delta        F1  Precision  Recall       IoU  #overlaps\n",
       "0  106506      0  0.000000   0.000000    0.00  0.000000          0\n",
       "1   98325      0  0.166667   0.333333    0.25  0.166667          5\n",
       "2  106533      0  0.060000   0.200000    0.15  0.096774          3\n",
       "3   90158      0  0.166667   0.333333    0.25  0.166667          5\n",
       "4   90162      0  0.426667   0.533333    0.40  0.296296          8\n",
       "5   98356      0  0.326667   0.466667    0.35  0.280000          7\n",
       "6  106560      0  0.150000   0.500000    0.15  0.130435          3\n",
       "7  106565      0  0.000000   0.000000    0.00  0.000000          0\n",
       "8   98377      0  0.500000   0.500000    0.50  0.333333          1\n",
       "9   90195      0  0.514286   0.600000    0.45  0.346154          9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrastive Keyword Extraction pipeline is being ran with combination 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [03:09<01:24,  6.49s/it]"
     ]
    }
   ],
   "source": [
    "create_cartesian_collection(parameters,\n",
    "                            df,\n",
    "                            all_usefull_ids[:50],\n",
    "                            baseline_ke_extractor = keyword_extraction.extract_yake,\n",
    "                            num_keywords=15,\n",
    "                            max_ngram=3,\n",
    "                            use_furthest=True, # only compare the first and last document\n",
    "                            make_data_persistent=True,\n",
    "                            path=\"combination\",\n",
    "                            compare_k = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f54d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9b538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
