{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23847f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from policy_processing import *\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import difflib\n",
    "from cleantext import clean\n",
    "import nltk\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c79268f",
   "metadata": {},
   "source": [
    "# Helper Functions to create the Html Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97917d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_html_collection(documents, site_nr, domain,wc = 80):\n",
    "    \n",
    "    versions = len(documents)\n",
    "    file_name = f\"HTML_DIFFS/policy_{site_nr}_collection.html\"\n",
    "    \n",
    "    html = \"\"\n",
    "    \n",
    "    for version in range(versions - 1):\n",
    "        a = sentences = nltk.sent_tokenize(documents[version])\n",
    "        b = sentences = nltk.sent_tokenize(documents[version + 1])\n",
    "        difference = difflib.HtmlDiff(wrapcolumn=wc)\n",
    "\n",
    "        \n",
    "        with open(file_name, \"a\") as file:\n",
    "            html = f\"<h1>{domain}</h1>\"\n",
    "            \n",
    "            html += difference.make_file(fromlines=a, \n",
    "                                        tolines=b, \n",
    "                                        fromdesc=f\"version {version}\", \n",
    "                                        todesc=f\"version {version + 1}\")\n",
    "            \n",
    "            file.write(html)\n",
    "    \n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a904e6ed",
   "metadata": {},
   "source": [
    "# Read in and clean the Policy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bb5cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_func = lambda text : clean(text,\n",
    "    fix_unicode=True,               # fix various unicode errors\n",
    "    to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "    lower=False,                     # lowercase text\n",
    "    no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them\n",
    "    no_urls=False,                  # replace all URLs with a special token\n",
    "    no_emails=False,                # replace all email addresses with a special token\n",
    "    no_phone_numbers=False,         # replace all phone numbers with a special token\n",
    "    no_numbers=False,               # replace all numbers with a special token\n",
    "    no_digits=False,                # replace all digits with a special token\n",
    "    no_currency_symbols=False,      # replace all currency symbols with a special token\n",
    "    no_punct=False,                 # remove punctuations\n",
    "    replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
    "    replace_with_url=\"<URL>\",\n",
    "    replace_with_email=\"<EMAIL>\",\n",
    "    replace_with_phone_number=\"<PHONE>\",\n",
    "    replace_with_number=\"<NUMBER>\",\n",
    "    replace_with_digit=\"0\",\n",
    "    replace_with_currency_symbol=\"<CUR>\",\n",
    "    lang=\"en\"              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20de0cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('../datasets/small10k.sqlite')\n",
    "df = pd.read_sql(\"SELECT * FROM small10k\", con=conn)\n",
    "all_site_ids = list(set(df.site_id))\n",
    "\n",
    "number_of_files_to_create = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "850a3211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  3.60it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in trange(number_of_files_to_create):\n",
    "    \n",
    "    site_id = all_site_ids[i]\n",
    "    \n",
    "    # sort first by year, then by phase\n",
    "    data = create_data(df.sort_values(by=['year', 'phase']), site_id)\n",
    "    \n",
    "    # get_the actual strings\n",
    "    policy_texts = get_policy_texts(data)\n",
    "\n",
    "    # cleaned documents using above function\n",
    "    documents = clean_text(policy_texts, cleaning_func)\n",
    "    \n",
    "    create_html_collection(documents, site_id, data[\"domain\"].values[0] ,wc = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9582ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff19db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ac3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
